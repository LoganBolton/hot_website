<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <!-- <link rel="favicon" type="image/x-icon" href="assets/images/highlighter.png"> -->
    <!-- <link rel="icon" type="image/x-icon" href="assets/images/highlighter.png"> -->
    <link rel="icon" type="image/png" href="assets/images/highlighter.png">
    <link rel="icon" type="image/x-icon" href="assets/images/highlighter.png">
    <link rel="shortcut icon" href="assets/images/highlighter.png">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HoT: Highlighted Chain of Thought</title>
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Clarity: A Minimalist Website Template for AI Research">
    <meta name="twitter:image:src" content="assets/figures/clarity.png">

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script> <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title">
            <div class="blog-intro">
                <div>
                    <div class="titleContainer">
                        <h1 class="title">HoT: Highlighted Chain of Thought for Referencing Supportive Facts from Inputs</h1>
                        <img class="logoContainer" src="assets/images/highlighter.png">
                    </div>
                    <p class="author"><a href="">Tin Nguyen</a>, <a href="">Logan Bolton</a>, <a href="">Mohammad Reza Taesiri</a>, <a href="">Anh Totti Nguyen</a></p>
                    <p class="abstract">
                        An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate non-factual statements. A response mixed of factual and non-factual statements poses a challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), <b>a technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the query</b>. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input. Interestingly, in few-shot settings, <b>HoT outperforms vanilla chain of thought prompting</b> (CoT) (Wei et al., 2022)on a wide range of 17 tasks from arithmetic, reading comprehension to logical reasoning. We also test how much highlights help users detect when LLMs are correct. As expected, they <b>help time-limited human participants to more accurately and efficiently recognize when LLMs are correct</b>. However, interestingly, when LLMs are wrong, HoTs tend to fool users into believing that an answer is correct.
                    </p>
                   
                </div>
               
                <div class="info flex">
                    <div class="main-buttons">
                        <a href="https://github.com/lorenmt/clarity-template" class="button icon" style="background-color: rgba(255, 255, 255, 0.25); margin-bottom: 0;">Paper <i class="fa-solid fa-book"></i></a>
                        <a href="https://github.com/lorenmt/clarity-template" class="button icon" style="background-color: rgba(255, 255, 255, 0.25); margin-bottom: 0;">Source Code <i class="fa-solid fa-code"></i></a>
                    </div>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="assets/figures/teaser2.png">
                <p class="caption">HoT consistently improves accuracy across 5 models and 17 datasets. In arithmetic, question-answering, and logical reasoning problems, HoT achieves +1.60, +2.58, and +2.53 percentage points, respectively, as compared to vanilla few-shot CoT.</p>
                <!-- <img class="background" src="assets/figures/teaser2.png"> -->
                <!-- <img class="foreground" src="assets/figures/clarity.png"> -->
                <!-- <img class="background" src="assets/figures/clarity.png"> -->
            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1>
            Introduction
        </h1>
        <p class='text'>
           Modern LLMs can bold, italicize or underline their text. Why not highlight as well? We propose Highlighted Chain-of-Thought Prompting (HoT), a technique for prompting LLMs to generate highlights around their responses that links specific information from the user query to the LLM response. 
        </p>

    </div>

    <div class="container blog main">
        <h2 >
            Key Takeaways
        </h2>
        <!-- <p class="text">
            In Clarity, I have provided container widths with five options: <code>main</code>, <code>large</code>, <code>extra-large</code>, <code>extra-extra-large</code>, and <code>max</code>. These container layouts are designed to be responsive, automatically adjusting based on the screen size.  The default width is <code>main</code>, which is used for this blog post. Be cautious when using the <code>max</code> option, as it has zero padding. Unless you are certain of the design, it's always recommended to leave some space for visual aesthetic purposes.
        </p> -->

        <ul>
            <li><b>HoT consistently improves accuracy</b> across 5 models and 17 datasets. 
                In arithmetic, question-answering, and logical reasoning problems, HoT achieves <span class="good">+1.60</span>, <span class="good">+2.58</span>, and <span class="good">+2.53</span> percentage points, respectively, as compared to vanilla few-shot CoT.</li>
            <li>Highlighted answers from HoT <b>improve human verification accuracy</b> by <span class="good">5.66</span> points (78.82% to 84.48%) and <b>reduce verification time</b> by <span class="good">-15.12 seconds</span> per question (62.38 seconds to 47.26 seconds) when assessing correct LLM responses compared to CoT answers</li>
            <li>Larger models generate highlights that <b>closely mirror human annotations</b> without requiring fine tuning.</li>
        </ul>

        <!-- <p class="text">
        Here is an example I designed, illustrating the architectural details in <a href="https://shikun.io/projects/prismer">Prismer</a> using the <code>extra-large</code> container width.
        </p> -->
    </div>



    <!-- <div class="container blog main">
        <h1 >
            Containers and Visual Diagrams
        </h1>

        <p class="text">
            Most AI projects incorporate visual diagrams to effectively communicate complex concepts. These diagrams often highlight new neural architecture designs and ML training pipelines, which are central to the project's contributions and research highlights. Clear and well-designed diagrams can significantly enhance the reader's understanding and engagement with the research. In Clarity, texts and visual diagrams are wrapped within a div container to maintain consistent design layouts.
        </p>      
        
        <p class="text">
            Simple design modules, such as minor adjustments to a neural network block, can be directly embedded within the text in the same container, without additional captions. This approach helps readers comprehend the proposed concept in a seamless and integrated manner.
        </p>

        <p class="text">
            Here is an example I redesigned, illustrating the difference between standard and bottleneck residual blocks as proposed in <a href="https://arxiv.org/abs/1512.03385">Residual Networks</a>.
        </p>

        <img src="clarity/images/residual.png" style="width: 80%;">

        <p class="text">
            For more complex visual diagrams, such as detailed neural architecture designs, it is recommended to use a separate container with a distinct background colour. This ensures that diagrams stand out and are easily distinguishable from the main text. Additionally, a new caption style is provided to help explain each design detail clearly.
        </p>

        <p class="text">
        Here is an example I redesigned, illustrating the architectural details in <a href="https://arxiv.org/abs/2010.11929">Vision Transformers (ViTs)</a>.
        </p>
    </div> -->


    <div class="container blog main">
        <h2 >
            Benchmark Improvements
        </h2>
        <img src="assets/images/math.png">
        <p class="caption">
            HoT consistently improves accuracy over CoT across arithmetic tasks. Notably, HoT achieves the largest performance gains in AQUA (+14.64 for ) and r-GSM (+12.73 for ).  
        </p>
    </div>
    <div class="container blog main">
        <img src="assets/images/qa.png">
        <p class="caption">
            HoT consistently improves accuracy over CoT across arithmetic tasks. Notably, HoT achieves the largest performance gains in AQUA (+14.64 for ) and r-GSM (+12.73 for ).  
        </p>
    </div>
    <div class="container blog main">
        <img src="assets/images/logic.png">
        <p class="caption">
            HoT consistently improves accuracy over CoT across arithmetic tasks. Notably, HoT achieves the largest performance gains in AQUA (+14.64 for ) and r-GSM (+12.73 for ).  
        </p>
    </div>
    

    <div class="container blog main gray">
        <h2 >
            Container Layouts
        </h2>
        <p class="text">
            In Clarity, I have provided container widths with five options: <code>main</code>, <code>large</code>, <code>extra-large</code>, <code>extra-extra-large</code>, and <code>max</code>. These container layouts are designed to be responsive, automatically adjusting based on the screen size.  The default width is <code>main</code>, which is used for this blog post. Be cautious when using the <code>max</code> option, as it has zero padding. Unless you are certain of the design, it's always recommended to leave some space for visual aesthetic purposes.
        </p>

        <p class="text">
        Here is an example I designed, illustrating the architectural details in <a href="https://shikun.io/projects/prismer">Prismer</a> using the <code>extra-large</code> container width.
        </p>
    </div>

    <div class="container blog extra-large gray">
        <div class="columns-2">
            <img src="assets/images/ex1.png" style="width: 100%">
            <img src="assets/images/ex2.png" style="width: 100%">
        </div>
    </div>
    <!-- <div class="container blog extra-large gray">
        <img src="clarity/images/prismer.png">
        <p class="caption">
            Prismer has two main trainable components: the <b>Experts Resampler</b> that converts variable multi-task signals to a fixed number of outputs, and the <b>Adaptor</b> that enhances the model's expressivity for vision-language reasoning. To ensure that the model takes advantage of the rich domain-specific knowledge encoded in the pre-trained experts, the majority of network weights are frozen during training, as represented by the snowflake icon.
        </p>
    </div> -->
    <div class="container blog main">
        <h2>Method</h2>
        <p class="text">
            HoT is a simple yet effective technique for prompting LLMs to generate highlighted responses. Given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input.
        </p>
        <div class="container blog extra-large">
            <div class="columns-1">
                <img src="assets/images/tags.png" style="width: 100%">
            </div>
        </div>
    </div>
    <div class="container blog main">

        <h2>
            Human Study
        </h2>

        <p class="text">
            We conducted a human study to evaluate the effectiveness of HoT in helping users detect when LLMs are correct. We found that HoT helps time-limited human participants to more accurately and efficiently recognize when LLMs are correct. However, when LLMs are wrong, HoTs tend to fool users into believing that an answer is correct.
            
            <!-- <div class="table-wrapper">
                <table>
                    <thead class="center">
                        <tr>
                            <th>Params</th>
                            <th >Dimension</th>
                            <th>$n$ heads</th>
                            <th>$n$ layers</th>
                            <th >Learning Rate</th>
                            <th>Batch Size</th>
                            <th>$n$ Tokens</th>
                        </tr>
                    </thead>
                    <tbody class="center">
                        <tr>
                            <td>6.7B</td>
                            <td>4096</td>
                            <td>32</td>
                            <td>32</td>
                            <td>$3e^{-4}$</td>
                            <td>4M</td>
                            <td>1T</td>
                        </tr>
                        <tr>
                            <td>13.0B</td>
                            <td>5120</td>
                            <td>40</td>
                            <td>40</td>
                            <td>$3e^{-4}$</td>
                            <td>4M</td>
                            <td>1T</td>
                        </tr>
                        <tr>
                            <td>32.5B</td>
                            <td>6656</td>
                            <td>52</td>
                            <td>60</td>
                            <td>$1.5e^{-4}$</td>
                            <td>4M</td>
                            <td>1T</td>
                        </tr>
                        <tr>
                            <td>65.2B</td>
                            <td>8192</td>
                            <td>64</td>
                            <td>80</td>
                            <td>$1.5e^{-4}$</td>
                            <td>4M</td>
                            <td>1T</td>
                        </tr>
                    </tbody>
                </table>
            </div> -->
            
            <div class="table-wrapper">
                <table>
                <thead class="center">
                    <tr>
                    <th>Prompt</th>
                    <th>Avg Time (seconds)</th>
                    <th>Accuracy (%)<br>LLM is Correct ✓</th>
                    <th>Accuracy (%)<br>LLM is Incorrect ✗</th>
                    </tr>
                </thead>
                <tbody class="center">
                    <tr>
                    <td>HoT</td>
                    <td><b>47.26</b></td>
                    <td><b>84.48 &plusmn; 20.28</b></td>
                    <td>54.83 &plusmn; 30.13</td>
                    </tr>
                    <tr>
                    <td>CoT</td>
                    <td>62.38</td>
                    <td>78.82 &plusmn; 28.26</td>
                    <td><b>72.21 &plusmn; 21.99</b></td>
                    </tr>
                </tbody>
                </table>
            </div>
            
        </p>
    </div>

    <div class="container blog main">
        <h2>
           Adding XML Tags to LLM Responses Boosts Performance
        </h2>
        <p class="text">
            We found that adding XML tags to LLM responses significantly boosts performance across a wide range of tasks. In particular, we observed that the highlights generated by HoT closely mirror human annotations
        </p>
    </div>

    <div class="container blog main">
        <h2>
            Limitations
        </h2>
        <p class="text">
            HoT is not a silver bullet. It is important to note that HoT is not a panacea for all LLM problems. In some cases, HoT may not be able to generate highlights that accurately reflect the user query. In such cases, it is recommended to use other techniques, such as fine-tuning or data augmentation, to improve the model's performance.
        </p>
    </div>

    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>